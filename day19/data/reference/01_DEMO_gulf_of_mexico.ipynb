{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5016222c-ce60-43ea-b83f-cf3e82da7507",
   "metadata": {},
   "source": [
    "# üåä Maritime Noise Analysis - DEMONSTRATION\n",
    "## Gulf of Mexico | Proof of Concept\n",
    "\n",
    "### ‚ö†Ô∏è IMPORTANT: This is a DEMONSTRATION\n",
    "This notebook uses **NOAA AIS data from the Gulf of Mexico** to demonstrate:\n",
    "- ‚úÖ JOMOPANS-ECHO model implementation\n",
    "- ‚úÖ 250m grid methodology  \n",
    "- ‚úÖ Complete analysis pipeline\n",
    "- ‚úÖ Export capabilities (Folium, Mundi)\n",
    "\n",
    "**The same methodology will be applied to Swedish waters** when HELCOM data is obtained.\n",
    "\n",
    "### Why Gulf of Mexico?\n",
    "- Available data NOW (NOAA public dataset)\n",
    "- Validates model and pipeline\n",
    "- Generates example visualizations\n",
    "- Proves concept for hackathon\n",
    "\n",
    "## Step 1: Load Available Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0285c6b4-27cf-41f5-85bd-355c7b681ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data Loader initialized\n",
      "   Path: /Users/raphaelanawa/Documents/GitHub/GIS_SymphonyLayer/data/raw/NOAA\n",
      "   Required columns: MMSI, BaseDateTime, LAT, LON, SOG, VesselType, Length\n",
      "üìÅ Available NOAA AIS files:\n"
     ]
    }
   ],
   "source": [
    "# Initialize data loader\n",
    "loader = AISDataLoader(data_path=data_raw)\n",
    "\n",
    "# List available files\n",
    "print(\"üìÅ Available NOAA AIS files:\")\n",
    "available_files = sorted(data_raw.glob(\"AIS_*.csv\"))\n",
    "for i, file in enumerate(available_files[:5], 1):\n",
    "    print(f\"   {i}. {file.name}\")\n",
    "\n",
    "if len(available_files) > 5:\n",
    "    print(f\"   ... and {len(available_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320e76c-9519-4992-97ea-7a1b67671460",
   "metadata": {},
   "source": [
    "## Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67fd3611-48ac-42f8-add7-f42fe5826c46",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GIS_SymphonyLayer/data/raw/NOAA/AIS_2024_01_01.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_available = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGIS_SymphonyLayer/data/raw/NOAA/AIS_2024_01_01.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Carregado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_available)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m registros\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìã Colunas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df_available.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/hackathon_shipnoise/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/hackathon_shipnoise/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/hackathon_shipnoise/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/hackathon_shipnoise/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/hackathon_shipnoise/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'GIS_SymphonyLayer/data/raw/NOAA/AIS_2024_01_01.csv'"
     ]
    }
   ],
   "source": [
    "# Load first available file as demonstration\n",
    "if available_files:\n",
    "    sample_file = available_files[0]\n",
    "    print(f\"\\nüî• Loading demonstration file: {sample_file.name}\\n\")\n",
    "    \n",
    "    df_raw = loader.load_noaa_ais(filename=sample_file.name)\n",
    "    \n",
    "    if df_raw is not None:\n",
    "        print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå No AIS data files found in the directory\")\n",
    "    print(f\"   Expected location: {data_raw}\")\n",
    "    print(\"\\nüìù Please ensure NOAA AIS CSV files are placed in this directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978da878-a84f-43ce-a240-02177625ed32",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning & Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521f558-c456-4f05-b608-e8d5a0efd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw data in loader\n",
    "loader.df = df_raw\n",
    "\n",
    "# Apply data quality filters (removes invalid data, keeps ALL vessel types)\n",
    "df_clean = loader.clean_data()\n",
    "\n",
    "# Explore cleaned data\n",
    "loader.explore_data(detailed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b4e0fa-4a54-4530-8758-4fb243b33560",
   "metadata": {},
   "source": [
    "## Step 4: Geographic Focus Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7fec1-c86e-48ca-b24d-d2971d964299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define area of interest (Gulf of Mexico example)\n",
    "# For Swedish waters, these bounds will change to Baltic Sea coordinates\n",
    "\n",
    "print(\"\\nüéØ Selecting Geographic Focus Area...\")\n",
    "print(\"   (For demo: Gulf of Mexico)\")\n",
    "print(\"   (For production: Swedish/Baltic Sea waters)\\n\")\n",
    "\n",
    "# Gulf of Mexico sample area (adjust based on your data)\n",
    "DEMO_BOUNDS = {\n",
    "    'min_lon': -95.0,\n",
    "    'max_lon': -88.0,\n",
    "    'min_lat': 27.0,\n",
    "    'max_lat': 30.0\n",
    "}\n",
    "\n",
    "# Apply geographic filter\n",
    "df_filtered = loader.filter_geographic_area(\n",
    "    min_lon=DEMO_BOUNDS['min_lon'],\n",
    "    max_lon=DEMO_BOUNDS['max_lon'],\n",
    "    min_lat=DEMO_BOUNDS['min_lat'],\n",
    "    max_lat=DEMO_BOUNDS['max_lat']\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Filtered Data Summary:\")\n",
    "print(f\"   Records: {len(df_filtered):,}\")\n",
    "print(f\"   Unique vessels: {df_filtered['MMSI'].nunique():,}\")\n",
    "print(f\"   Geographic extent: {DEMO_BOUNDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6623644-ad93-438b-b144-1c4827bbca71",
   "metadata": {},
   "source": [
    "## Step 5: Vessel Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86fa987-efea-455b-8b52-7e9a760d47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüö¢ Classifying vessels using JOMOPANS-ECHO model...\\n\")\n",
    "\n",
    "# Apply vessel classification\n",
    "df_filtered['vessel_class'] = df_filtered.apply(\n",
    "    lambda row: classify_vessel_from_ais(\n",
    "        ais_type=row['VesselType'],\n",
    "        speed_kn=row['SOG'],\n",
    "        length_m=row['Length']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show classification results\n",
    "print(\"üìä Vessel Classification Summary:\")\n",
    "print(\"=\"*60)\n",
    "class_counts = df_filtered['vessel_class'].value_counts()\n",
    "for vessel_type, count in class_counts.items():\n",
    "    pct = count / len(df_filtered) * 100\n",
    "    print(f\"   {vessel_type:<20} {count:>8,} ({pct:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\n   {'Total':<20} {len(df_filtered):>8,} (100.0%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328665c-dc71-4462-9bbb-4af888214822",
   "metadata": {},
   "source": [
    "## Step 6: Calculate Noise Emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc96315-75cd-44db-a30a-805602a57c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîä Calculating 125 Hz noise emissions for each vessel position...\\n\")\n",
    "\n",
    "# Calculate noise emission for each AIS record\n",
    "df_filtered['emission_125hz_dB'] = df_filtered.apply(\n",
    "    lambda row: calculate_125hz_emission(\n",
    "        vessel_type=row['vessel_class'],\n",
    "        speed_kn=row['SOG'],\n",
    "        length_m=row['Length']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Noise emissions calculated!\")\n",
    "print(\"\\nüìä Emission Statistics:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"   Mean:     {df_filtered['emission_125hz_dB'].mean():.1f} dB re 1 ¬µPa @ 1m\")\n",
    "print(f\"   Median:   {df_filtered['emission_125hz_dB'].median():.1f} dB\")\n",
    "print(f\"   Std Dev:  {df_filtered['emission_125hz_dB'].std():.1f} dB\")\n",
    "print(f\"   Min:      {df_filtered['emission_125hz_dB'].min():.1f} dB\")\n",
    "print(f\"   Max:      {df_filtered['emission_125hz_dB'].max():.1f} dB\")\n",
    "\n",
    "# Show emission by vessel class\n",
    "print(\"\\nüìà Average Emission by Vessel Class:\")\n",
    "print(\"=\"*60)\n",
    "emission_by_class = df_filtered.groupby('vessel_class')['emission_125hz_dB'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
    "for vessel_class, row in emission_by_class.iterrows():\n",
    "    print(f\"   {vessel_class:<20} {row['mean']:>6.1f} dB  (n={int(row['count']):,})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee82cfb9-3262-4e84-b196-14637e21cf03",
   "metadata": {},
   "source": [
    "## Step 7: Create Spatial Grid (250m √ó 250m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf59cc87-7f3d-4198-bcc6-78224f6fb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüó∫Ô∏è Creating 250m √ó 250m spatial grid...\\n\")\n",
    "\n",
    "# Create grid generator\n",
    "grid_generator = GridGenerator(\n",
    "    bounds=(\n",
    "        DEMO_BOUNDS['min_lon'],\n",
    "        DEMO_BOUNDS['min_lat'],\n",
    "        DEMO_BOUNDS['max_lon'],\n",
    "        DEMO_BOUNDS['max_lat']\n",
    "    ),\n",
    "    cell_size_km=0.25  # 250 meters\n",
    ")\n",
    "\n",
    "# Generate grid\n",
    "grid = grid_generator.create_grid()\n",
    "\n",
    "print(f\"\\n‚úÖ Grid created successfully!\")\n",
    "print(f\"   Total cells: {len(grid):,}\")\n",
    "print(f\"   Cell size: 250m √ó 250m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46727ef-efc1-47eb-b483-4e877ff946c4",
   "metadata": {},
   "source": [
    "## Step 8: Spatial Analysis - Assign to Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384b1e4-40a5-4846-b96a-8f7d28ee6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìç Assigning vessel positions to grid cells...\\n\")\n",
    "\n",
    "# Initialize spatial analyzer\n",
    "spatial_analyzer = SpatialNoiseAnalyzer(grid_generator)\n",
    "\n",
    "# Assign positions to grid cells\n",
    "gdf_with_cells = spatial_analyzer.assign_positions_to_grid(df_filtered)\n",
    "\n",
    "print(f\"\\n‚úÖ Spatial assignment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a672e8-2540-4565-8565-af9488bc144d",
   "metadata": {},
   "source": [
    "## Step 9: Calculate Grid-Level Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74794521-bcc5-4750-9680-9d1a5bee6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Calculating noise metrics for each grid cell...\\n\")\n",
    "\n",
    "# Calculate aggregated metrics per cell\n",
    "grid_noise = spatial_analyzer.calculate_grid_noise_metrics(gdf_with_cells)\n",
    "\n",
    "print(f\"\\n‚úÖ Grid metrics calculated!\")\n",
    "\n",
    "# Show top noise hotspots\n",
    "hotspots = spatial_analyzer.analyze_noise_hotspots(grid_noise, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af19138-59d2-4fcd-8c4c-d21d28aa9c84",
   "metadata": {},
   "source": [
    "## Step 10: Visualization - Static Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258ddb0-a911-407c-bba2-e4b971c86318",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìà Creating static visualizations...\\n\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = spatial_analyzer.plot_noise_grid(\n",
    "    grid_noise, \n",
    "    title=\"Gulf of Mexico Maritime Noise Analysis - DEMONSTRATION\"\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Static plots created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3665a640-46f9-4659-87bd-52806b10bb55",
   "metadata": {},
   "source": [
    "## Step 12: Export Complete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcbbea-e458-4d15-aadb-6252081972d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüåê Creating interactive Folium map...\\n\")\n",
    "\n",
    "# Create output directory\n",
    "viz_dir = data_outputs / 'demo_visualizations'\n",
    "viz_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Export Folium map\n",
    "folium_map = export_for_folium(\n",
    "    grid_noise,\n",
    "    output_path=viz_dir / 'gulf_of_mexico_noise_demo.html',\n",
    "    center=None  # Auto-calculate center\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Interactive map created!\")\n",
    "print(f\"   üìÇ Location: {viz_dir / 'gulf_of_mexico_noise_demo.html'}\")\n",
    "print(f\"\\n   üåê Open the HTML file in your browser to explore!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e8315a-de9a-41ef-88ad-f2284323ba63",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38822ff0-207b-4ced-a96b-b1243255dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final summary\n",
    "cells_with_data = grid_noise[grid_noise['vessel_count'] > 0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è  GRID COVERAGE:\")\n",
    "print(f\"   Total grid cells: {len(grid_noise):,}\")\n",
    "print(f\"   Cells with data: {len(cells_with_data):,} ({len(cells_with_data)/len(grid_noise)*100:.1f}%)\")\n",
    "print(f\"   Empty cells: {len(grid_noise) - len(cells_with_data):,}\")\n",
    "\n",
    "print(f\"\\nüö¢ VESSEL ACTIVITY:\")\n",
    "print(f\"   Total observations: {int(grid_noise['vessel_count'].sum()):,}\")\n",
    "print(f\"   Unique vessels: {df_filtered['MMSI'].nunique():,}\")\n",
    "print(f\"   Max vessels per cell: {int(grid_noise['vessel_count'].max())}\")\n",
    "\n",
    "print(f\"\\nüîä NOISE LEVELS (125 Hz):\")\n",
    "print(f\"   Mean: {cells_with_data['noise_mean'].mean():.1f} dB re 1 ¬µPa @ 1m\")\n",
    "print(f\"   Median: {cells_with_data['noise_median'].median():.1f} dB\")\n",
    "print(f\"   Range: {cells_with_data['noise_min'].min():.1f} - {cells_with_data['noise_max'].max():.1f} dB\")\n",
    "\n",
    "print(f\"\\nüéØ TOP NOISE HOTSPOT:\")\n",
    "top_cell = cells_with_data.nlargest(1, 'noise_mean').iloc[0]\n",
    "print(f\"   Cell ID: {int(top_cell['cell_id'])}\")\n",
    "print(f\"   Average noise: {top_cell['noise_mean']:.1f} dB\")\n",
    "print(f\"   Vessel count: {int(top_cell['vessel_count'])}\")\n",
    "print(f\"   Dominant type: {top_cell['dominant_vessel_type']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ DEMONSTRATION SUCCESSFUL!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "print(\"   1. Review interactive map in browser\")\n",
    "print(\"   2. Analyze exported GeoJSON/CSV data\")\n",
    "print(\"   3. Apply same methodology to HELCOM data for Swedish waters\")\n",
    "print(\"   4. Customize analysis parameters as needed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
