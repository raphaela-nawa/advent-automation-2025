# ğŸ”„ Pipeline Atualizado - Day 05

## âš ï¸ CORREÃ‡ÃƒO CRÃTICA APLICADA

O pipeline foi corrigido para fazer **extraÃ§Ã£o completa do catÃ¡logo** ao invÃ©s de busca limitada.

---

## ğŸ“‹ Novo Fluxo de ExecuÃ§Ã£o

### Passo 1: Transcrever Ãudios (30 min)
```bash
python day05_DATA_transcribe_whisper.py
```
**Output:** Transcripts em `data/raw/transcripts/`

---

### Passo 2: Extrair MenÃ§Ãµes com GPT-4 (25 min)
```bash
python day05_PIPELINE_extract_items.py
```
**Output:** `data/processed/items_to_validate.csv`

---

### Passo 3: **[NOVO]** Extrair CatÃ¡logo Completo (45 min)
```bash
python day05_DATA_extract_complete_catalog.py
```

**O que faz:**
- âœ… Descobre total de itens no acervo (estimado: 2000+)
- âœ… Extrai **TODOS** os itens com paginaÃ§Ã£o
- âœ… Salva em database SQLite local
- âœ… Valida completude (>95%)

**Output:** `data/processed/museu_paulista_completo.db`

**Estimativa:**
- Total esperado: **2000-5000+ itens**
- Fotos do MilitÃ£o: **333+ itens**
- Tempo de extraÃ§Ã£o: **30-45 min**

---

### Passo 4: ValidaÃ§Ã£o Manual (15 min)
```bash
# Abrir CSV manualmente
open data/processed/items_to_validate.csv
```

**AÃ§Ãµes:**
1. Revisar cada `item_mention`
2. Marcar `validated` como `yes` ou `no`
3. Salvar arquivo

---

### Passo 5: **[ATUALIZADO]** Busca Local (10 min)
```bash
python day05_DATA_search_local_db.py
```

**MudanÃ§as:**
- âŒ ~~Busca via API limitada~~
- âœ… Busca no database SQLite completo
- âœ… Fuzzy matching com **TODOS** os itens
- âœ… Melhor precisÃ£o de matching

**Output:** `data/processed/matched_items.csv`

---

### Passo 6: Load para BigQuery (5 min)
```bash
python day05_DATA_load_bigquery.py
```
**Output:** BigQuery table `podcast_museum_mentions`

---

## ğŸ“Š ValidaÃ§Ã£o de Sucesso

### ApÃ³s Passo 3 (ExtraÃ§Ã£o Completa):
```bash
python -c "
import sqlite3
conn = sqlite3.connect('data/processed/museu_paulista_completo.db')
total = conn.execute('SELECT COUNT(*) FROM items').fetchone()[0]
print(f'âœ… Total de itens no DB: {total:,}')
print(f'Esperado: >2000 itens')
conn.close()
"
```

### ApÃ³s Passo 5 (Busca Local):
```bash
python -c "
import pandas as pd
df = pd.read_csv('data/processed/matched_items.csv')
matched = df['matched'].sum()
total = len(df)
print(f'âœ… Matched: {matched}/{total}')
print(f'Taxa de match: {matched/total*100:.1f}%')
"
```

---

## ğŸ¯ CritÃ©rios de Sucesso Final

- âœ… Database SQLite com **2000+ itens**
- âœ… **>80%** de completude vs total da API
- âœ… Fuzzy matching com confianÃ§a **>0.6**
- âœ… Dados carregados no BigQuery

---

## ğŸ“ Arquivos Gerados

```
day05/data/processed/
â”œâ”€â”€ items_to_validate.csv           # GPT extractions
â”œâ”€â”€ museu_paulista_completo.db      # NOVO: Full catalog
â”œâ”€â”€ extraction_stats.json           # NOVO: Stats
â”œâ”€â”€ matched_items.csv               # Search results
â””â”€â”€ final_bigquery_data.csv         # Final output
```

---

## â±ï¸ Tempo Total Atualizado

| Passo | Tempo | Total |
|-------|-------|-------|
| TranscriÃ§Ã£o | 30 min | 30 min |
| ExtraÃ§Ã£o GPT | 25 min | 55 min |
| **ExtraÃ§Ã£o Completa** | **45 min** | **100 min** |
| ValidaÃ§Ã£o Manual | 15 min | 115 min |
| Busca Local | 10 min | 125 min |
| BigQuery Load | 5 min | 130 min |
| **Total** | **~2h 10min** | |

---

## ğŸš€ Comando RÃ¡pido (Tudo em SequÃªncia)

```bash
cd day05

# Passo 1
python day05_DATA_transcribe_whisper.py

# Passo 2
python day05_PIPELINE_extract_items.py

# Passo 3 - NOVO!
python day05_DATA_extract_complete_catalog.py

# Passo 4 - MANUAL
echo "âš ï¸  Valide items_to_validate.csv manualmente!"
open data/processed/items_to_validate.csv

# Passo 5 - ATUALIZADO!
python day05_DATA_search_local_db.py

# Passo 6
python day05_DATA_load_bigquery.py
```

---

**Melhorias Implementadas:**
- âœ… ExtraÃ§Ã£o completa do acervo (2000+ itens)
- âœ… Database SQLite local para busca rÃ¡pida
- âœ… Fuzzy matching mais preciso
- âœ… Melhor taxa de correspondÃªncia
- âœ… Pipeline mais robusto
