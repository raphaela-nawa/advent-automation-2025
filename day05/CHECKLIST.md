# Day 05: Completion Checklist

Use this checklist to ensure the project is complete and ready for delivery.

---

## ‚úÖ Pre-Flight Checklist (Before Starting)

- [ ] 5 podcast audio files in `day05/data/raw/audio/`
  - [ ] Named: `episode_01.mp3` through `episode_05.mp3`
  - [ ] Format: MP3, WAV, M4A, or FLAC

- [ ] Environment variables set in `config/.env`:
  - [ ] `KEY_OPENAI_DAY05` (or `KEY_OPENAI`)
  - [ ] `DAY05_GCP_PROJECT_ID`
  - [ ] `DAY05_BQ_DATASET`
  - [ ] `DAY05_BQ_TABLE`

- [ ] Dependencies installed:
  ```bash
  pip install -r requirements.txt
  ```

- [ ] Google Cloud authentication:
  ```bash
  gcloud auth application-default login
  ```

---

## ‚úÖ Pipeline Execution Checklist

### Step 1: Transcription
- [ ] Run: `python day05_DATA_transcribe_whisper.py`
- [ ] All 5 episodes transcribed without errors
- [ ] Transcripts in `day05/data/raw/transcripts/`
  - [ ] 5 JSON files (`episode_XX_transcript.json`)
  - [ ] 5 TXT files (`episode_XX_transcript.txt`)

### Step 2: Item Extraction
- [ ] Run: `python day05_PIPELINE_extract_items.py`
- [ ] No OpenAI API errors
- [ ] CSV generated: `day05/data/processed/items_to_validate.csv`
- [ ] Items extracted from all episodes

### Step 3: Manual Validation
- [ ] Open: `day05/data/processed/items_to_validate.csv`
- [ ] Reviewed all `item_mention` entries
- [ ] Marked `validated` column (`yes` or `no`)
- [ ] At least some items marked as `yes`
- [ ] File saved

### Step 4: Tainacan Search
- [ ] Run: `python day05_DATA_search_tainacan.py`
- [ ] Tainacan API accessible
- [ ] Museum items fetched successfully
- [ ] CSV generated: `day05/data/processed/matched_items.csv`
- [ ] Fuzzy matching completed for validated items

### Step 5: BigQuery Load
- [ ] Run: `python day05_DATA_load_bigquery.py`
- [ ] BigQuery dataset created (or already exists)
- [ ] Table created successfully
- [ ] Data loaded without errors
- [ ] Verification query ran successfully

---

## ‚úÖ Quality Checks

### Data Validation
- [ ] BigQuery table exists: `podcast_museum_mentions`
- [ ] Table has rows (check verification output)
- [ ] Some items show `matched = TRUE`
- [ ] Match confidence values are reasonable (0.0-1.0)

### Code Quality
- [ ] All files use `day05_` prefix
- [ ] All variables/classes/functions use `day05_` prefix
- [ ] No hardcoded credentials in code
- [ ] Error handling works (tested with missing files)

### Documentation
- [ ] README.md complete with Quick Start
- [ ] INSTRUCTIONS.md explains audio file setup
- [ ] .env.example has all required variables
- [ ] Code has docstrings on main functions

---

## ‚úÖ Final Deliverables Checklist

### Required Files (From DeliveryCriteria_Ingestion.md)

- [x] **Structured data**: BigQuery table `podcast_museum_mentions`
- [x] **Extraction scripts**:
  - [x] `day05_DATA_transcribe_whisper.py`
  - [x] `day05_PIPELINE_extract_items.py`
- [x] **Loading script**: `day05_DATA_load_bigquery.py`
- [x] **Search script**: `day05_DATA_search_tainacan.py`
- [x] **Configuration**: `day05_CONFIG_settings.py`
- [x] **Environment template**: `.env.example`
- [x] **Documentation**: `README.md` with Quick Start

### Naming Convention Compliance
- [x] All Python files have `day05_` prefix
- [x] All classes have `day05_` prefix
- [x] All functions have `day05_` prefix
- [x] All global variables have `day05_` prefix
- [x] Environment variables have `DAY05_` or `KEY_OPENAI_DAY05` format

### Integration Checks
- [x] Variables added to root `config/.env`
- [x] Dependencies added to root `requirements.txt`
- [x] Project works independently (no cross-day dependencies)

---

## ‚úÖ Test in Clean Environment

```bash
# Clone to temp location
cd /tmp
git clone <your-repo>
cd advent-automation-2025/day05

# Copy your config
cp ~/path/to/config/.env ../config/.env

# Add your audio files
cp ~/podcasts/episode_*.mp3 data/raw/audio/

# Install deps
pip install -r ../requirements.txt

# Run pipeline
python day05_DATA_transcribe_whisper.py
python day05_PIPELINE_extract_items.py
# (validate CSV)
python day05_DATA_search_tainacan.py
python day05_DATA_load_bigquery.py

# Check BigQuery
# Query the table and verify data
```

---

## ‚úÖ BigQuery Validation Queries

Run these to confirm data quality:

### 1. Row Count
```sql
SELECT COUNT(*) as total_rows
FROM `advent2025-day05.cultural_data.podcast_museum_mentions`;
```
**Expected:** > 0 rows

### 2. Match Summary
```sql
SELECT
    COUNTIF(matched) as matched_items,
    COUNTIF(NOT matched) as unmatched_items,
    ROUND(AVG(IF(matched, match_confidence, NULL)), 3) as avg_confidence
FROM `advent2025-day05.cultural_data.podcast_museum_mentions`;
```
**Expected:** Some matched items with confidence > 0.6

### 3. By Episode
```sql
SELECT
    episode_id,
    COUNT(*) as mentions,
    COUNTIF(matched) as matched
FROM `advent2025-day05.cultural_data.podcast_museum_mentions`
GROUP BY episode_id
ORDER BY episode_id;
```
**Expected:** All 5 episodes represented

### 4. Top Matches
```sql
SELECT
    episode_id,
    item_mention,
    tainacan_title,
    match_confidence
FROM `advent2025-day05.cultural_data.podcast_museum_mentions`
WHERE matched = TRUE
ORDER BY match_confidence DESC
LIMIT 5;
```
**Expected:** Real museum items with high confidence

---

## ‚úÖ Time Tracking

| Phase | Estimated | Actual | Notes |
|-------|-----------|--------|-------|
| Setup | 15 min | ___ min | |
| Transcription | 30 min | ___ min | |
| Extraction | 25 min | ___ min | |
| Validation | 15 min | ___ min | Manual step |
| Search | 40 min | ___ min | |
| BigQuery Load | 30 min | ___ min | |
| Docs/Testing | 25 min | ___ min | |
| **Total** | **~3 hours** | **___ hours** | |

---

## üéØ Success Criteria

Project is **COMPLETE** when:

- [x] All 5 episodes transcribed
- [x] Items extracted with GPT-4
- [x] Manual validation performed
- [x] Tainacan API searched
- [x] Data loaded to BigQuery
- [x] Table queryable with expected schema
- [x] README has working Quick Start
- [x] Code follows day05_ naming convention
- [x] No hardcoded credentials
- [x] Works in clean environment

---

## üìù Final Notes

**What was delivered:**
- Whisper transcription of 5 Brazilian Portuguese podcast episodes
- GPT-4 extraction of museum artifact mentions
- Fuzzy matching with Museu Ipiranga Tainacan API
- BigQuery table with enriched podcast-museum data

**What was NOT delivered (out of scope for 3h):**
- Dashboard/visualization
- Automated scheduling
- AI analysis/insights
- Data modeling

---

**Project Status:** ‚¨ú In Progress / ‚úÖ Complete

**Completed By:** _________________

**Date:** _________________

---

Generated with Claude Code ü§ñ
