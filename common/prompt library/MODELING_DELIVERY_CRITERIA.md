# Delivery Criteria - Modeling Projects (Days 6-10)

## üìã DECISION MATRIX

### ‚úÖ MANDATORY OUTPUT (You MUST deliver this)

| Item | Description | Location |
|------|-------------|----------|
| **SQL model files** | `.sql` files with documented logic and business rules | `/dayXX/models/` or `/dayXX/sql/` |
| **Data model documentation** | ERD diagram or schema description | `/dayXX/docs/` or in README |
| **Sample queries** | Queries demonstrating the model in action | `/dayXX/queries/` or in README |
| **Reproducible config** | `.env.example` with day-specific variables | `/dayXX/.env.example` |
| **Dependencies** | Day-specific requirements (if needed) | `/dayXX/dayXX_requirements.txt` |
| **Minimal documentation** | README with Quick Start | `/dayXX/README.md` |

### ‚ùå FORBIDDEN OUTPUT (DON'T do this - will exceed 3h)

| Item | Why NOT |
|------|---------|
| **Dashboards/visualizations** | That's Pilar D (Dashboard) |
| **Orchestration/scheduling** | That's Pilar C (Orchestration) |
| **AI insights/predictions** | That's Pilar E (AI Insights) |
| **Data ingestion** | That's Pilar A (Ingestion) - assume data is already available |
| **Complex testing frameworks** | Only basic validation (< 30 min) |
| **Premature optimization** | Performance comes later, functionality first |
| **UI/Frontend** | CLI or SQL scripts only |

---

## ‚úÖ COMPLETE PROJECT CHECKLIST

### **BEFORE considering the project complete, verify:**

#### **1. Core Functionality**
- [ ] SQL models execute without errors
- [ ] Results match expected business logic
- [ ] Data model is documented (ERD or written description)

#### **2. Reproducibility** (following PROMPT_project_setup.md rules)
- [ ] `.env.example` lists ALL necessary variables (format: `DAYXX_DB_PATH`, `DAYXX_SPECIFIC_VAR`)
- [ ] Variables added to root `config/.env` following existing convention
- [ ] `dayXX_requirements.txt` has specific dependencies (if needed)
- [ ] README has "Quick Start" section that works copy-paste

#### **3. Minimum Quality**
- [ ] Code has docstrings explaining business logic
- [ ] Basic error handling (try/except where needed)
- [ ] Informative logs (print or logging showing progress)

#### **4. Naming Convention (CRITICAL)**
- [ ] All files have `dayXX_` prefix
- [ ] Global variables have `dayXX_` or `DAYXX_` prefix
- [ ] Classes have `dayXX_` prefix
- [ ] Main functions have `dayXX_` prefix

#### **5. Delivery**
- [ ] Git commit with descriptive message
- [ ] Push to GitHub

#### **6. Final Test (5 minutes)**
- [ ] Clone repo in another folder
- [ ] Run commands from README
- [ ] Works? ‚úÖ Project complete. Doesn't work? ‚ùå Debug and fix.

---

## ‚è±Ô∏è TIME MANAGEMENT (3 hours)

### **Ideal Distribution:**

| Phase | Time | What to Do |
|-------|------|------------|
| **Setup** | 15 min | Check to see if corresponding folder exists. If not, create dayXX/ folder, set up database/dbt, configure .env |
| **Model Development** | 120 min | Write SQL, test, iterate on business logic |
| **Documentation** | 30 min | README, comments, ERD (if applicable) |
| **Testing** | 15 min | Run queries, validate results |

### **üö® SIGNS YOU'RE DEVIATING FROM SCOPE:**

- You're building dashboards
- You're writing complex data validation frameworks
- You're doing exploratory data analysis
- You're optimizing performance before functionality works
- You're adding "cool features" not requested

**If this happens:** STOP. Return to requirements. Deliver the promised minimum first.

---

## üéØ PROJECT-SPECIFIC CRITERIA

### **Day 6 (Murilo - SaaS Health Metrics Foundation)**

**Stakeholder:** Murilo (Simetryk SaaS - originally Day 24)

**Project:** SaaS Health Metrics Foundation (SQL)

**Focus:** Churn, MRR, Retention - dados prontos para dashboard

**Data Sources:**
- Synthetic SaaS data (customers, subscriptions, MRR movements)
- 500 customers, 24 months history
- 3 plan tiers: Starter/Pro/Enterprise

**Mandatory Output:**
- [ ] SQLite database with 3 tables:
  - `day06_customers` (customer_id, signup_date, plan_tier, mrr_current, status)
  - `day06_subscriptions` (subscription_id, customer_id, start_date, end_date, mrr, plan_tier)
  - `day06_mrr_movements` (month, new_mrr, expansion_mrr, contraction_mrr, churn_mrr, net_mrr)
- [ ] 4 SQL Views ready for dashboard consumption:
  - `day06_mrr_summary` - MRR waterfall (New, Expansion, Contraction, Churn)
  - `day06_churn_by_cohort` - Churn rate by signup month and segment
  - `day06_retention_curves` - Cohort-based retention analysis
  - `day06_customer_health` - LTV/CAC and health scoring
- [ ] Sample queries demonstrating each metric
- [ ] README explaining each metric and connection to Dashboard (Day 19)

**When to Stop:**
- ‚úÖ 4 views created with clear business logic
- ‚úÖ MRR Movement correctly calculated (New + Expansion - Contraction - Churn = Net MRR)
- ‚úÖ Cohort analysis with at least 12 months of data
- ‚úÖ Churn rate calculated monthly and by segment (plan tier)
- ‚úÖ Window functions used for retention curves
- ‚úÖ Comments explaining SaaS metric subtleties
- ‚úÖ README explains "How Murilo uses this for SaaS health monitoring"
- ‚úÖ **Dashboard Integration**: Documentation showing which views connect to Day 19 dashboard
- ‚ùå DON'T do: Churn prediction (ML), real payment gateway integration, dunning management, ARR forecasting

**Expected Files:**
```
day06/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ day06_saas_metrics.db (SQLite)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ day06_MODEL_base_tables.sql (creates 3 base tables)
‚îÇ   ‚îî‚îÄ‚îÄ day06_MODEL_views.sql (creates 4 analytical views)
‚îú‚îÄ‚îÄ queries/
‚îÇ   ‚îú‚îÄ‚îÄ day06_QUERY_mrr_waterfall.sql
‚îÇ   ‚îú‚îÄ‚îÄ day06_QUERY_churn_analysis.sql
‚îÇ   ‚îú‚îÄ‚îÄ day06_QUERY_retention.sql
‚îÇ   ‚îî‚îÄ‚îÄ day06_QUERY_customer_health.sql
‚îú‚îÄ‚îÄ day06_DATA_synthetic_saas.py
‚îú‚îÄ‚îÄ day06_CONFIG_settings.py
‚îú‚îÄ‚îÄ day06_requirements.txt (if needed)
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

**Data Model Schema:**
```sql
-- Base Table 1: Customers
CREATE TABLE day06_customers (
    customer_id VARCHAR(50) PRIMARY KEY,
    signup_date DATE NOT NULL,
    plan_tier VARCHAR(20) CHECK (plan_tier IN ('Starter', 'Pro', 'Enterprise')),
    mrr_current DECIMAL(10,2),
    status VARCHAR(10) CHECK (status IN ('active', 'churned'))
);

-- Base Table 2: Subscriptions
CREATE TABLE day06_subscriptions (
    subscription_id VARCHAR(50) PRIMARY KEY,
    customer_id VARCHAR(50),
    start_date DATE NOT NULL,
    end_date DATE,
    mrr DECIMAL(10,2),
    plan_tier VARCHAR(20) CHECK (plan_tier IN ('Starter', 'Pro', 'Enterprise')),
    FOREIGN KEY (customer_id) REFERENCES day06_customers(customer_id)
);

-- Base Table 3: MRR Movements
CREATE TABLE day06_mrr_movements (
    month DATE PRIMARY KEY,
    new_mrr DECIMAL(10,2),
    expansion_mrr DECIMAL(10,2),
    contraction_mrr DECIMAL(10,2),
    churn_mrr DECIMAL(10,2),
    net_mrr DECIMAL(10,2)
);
```

**View Examples:**
```sql
-- View 1: MRR Summary (Waterfall)
CREATE VIEW day06_mrr_summary AS
WITH day06_monthly_changes AS (
    SELECT
        DATE_TRUNC('month', start_date) as month,
        SUM(CASE WHEN start_date = signup_date THEN mrr ELSE 0 END) as new_mrr,
        SUM(CASE WHEN start_date > signup_date AND mrr > prev_mrr THEN mrr - prev_mrr ELSE 0 END) as expansion_mrr,
        SUM(CASE WHEN start_date > signup_date AND mrr < prev_mrr THEN prev_mrr - mrr ELSE 0 END) as contraction_mrr,
        SUM(CASE WHEN end_date IS NOT NULL THEN mrr ELSE 0 END) as churn_mrr
    FROM day06_subscriptions s
    JOIN day06_customers c ON s.customer_id = c.customer_id
)
SELECT
    month,
    new_mrr,
    expansion_mrr,
    contraction_mrr,
    churn_mrr,
    (new_mrr + expansion_mrr - contraction_mrr - churn_mrr) as net_mrr
FROM day06_monthly_changes;

-- View 2: Churn by Cohort
CREATE VIEW day06_churn_by_cohort AS
WITH day06_cohorts AS (
    SELECT
        DATE_TRUNC('month', signup_date) as cohort_month,
        plan_tier,
        COUNT(*) as cohort_size,
        SUM(CASE WHEN status = 'churned' THEN 1 ELSE 0 END) as churned_count
    FROM day06_customers
    GROUP BY DATE_TRUNC('month', signup_date), plan_tier
)
SELECT
    cohort_month,
    plan_tier,
    cohort_size,
    churned_count,
    ROUND(100.0 * churned_count / cohort_size, 2) as churn_rate_pct
FROM day06_cohorts;

-- View 3: Retention Curves
CREATE VIEW day06_retention_curves AS
WITH day06_first_sub AS (
    SELECT
        customer_id,
        DATE_TRUNC('month', MIN(start_date)) as cohort_month
    FROM day06_subscriptions
    GROUP BY customer_id
),
day06_monthly_activity AS (
    SELECT
        fs.cohort_month,
        s.customer_id,
        DATE_TRUNC('month', s.start_date) as activity_month,
        DATEDIFF(MONTH, fs.cohort_month, DATE_TRUNC('month', s.start_date)) as months_since_signup
    FROM day06_first_sub fs
    JOIN day06_subscriptions s ON fs.customer_id = s.customer_id
)
SELECT
    cohort_month,
    months_since_signup,
    COUNT(DISTINCT customer_id) as retained_customers,
    ROUND(100.0 * COUNT(DISTINCT customer_id) /
          FIRST_VALUE(COUNT(DISTINCT customer_id)) OVER (
              PARTITION BY cohort_month
              ORDER BY months_since_signup
          ), 2) as retention_rate_pct
FROM day06_monthly_activity
GROUP BY cohort_month, months_since_signup;

-- View 4: Customer Health Score
CREATE VIEW day06_customer_health AS
WITH day06_customer_metrics AS (
    SELECT
        c.customer_id,
        c.plan_tier,
        c.mrr_current,
        DATEDIFF(MONTH, c.signup_date, CURRENT_DATE) as customer_age_months,
        (c.mrr_current * DATEDIFF(MONTH, c.signup_date, CURRENT_DATE)) as ltv_estimate,
        c.status
    FROM day06_customers c
)
SELECT
    customer_id,
    plan_tier,
    mrr_current,
    customer_age_months,
    ltv_estimate,
    -- Simple CAC assumption: $500 per customer
    ROUND(ltv_estimate / 500.0, 2) as ltv_cac_ratio,
    CASE
        WHEN status = 'churned' THEN 'Churned'
        WHEN ltv_estimate / 500.0 > 3 THEN 'Healthy'
        WHEN ltv_estimate / 500.0 > 1 THEN 'At Risk'
        ELSE 'Critical'
    END as health_status
FROM day06_customer_metrics;
```

**Dashboard Integration (Day 19):**
```markdown
## Connection to Day 19 Dashboard

The following views are designed to be consumed by the Dashboard project:

1. **day06_mrr_summary** ‚Üí MRR Waterfall Chart
   - X-axis: month
   - Y-axis: new_mrr, expansion_mrr, contraction_mrr, churn_mrr
   - Shows monthly MRR movement breakdown

2. **day06_churn_by_cohort** ‚Üí Churn Heatmap
   - Rows: cohort_month
   - Columns: plan_tier
   - Color: churn_rate_pct

3. **day06_retention_curves** ‚Üí Retention Line Chart
   - X-axis: months_since_signup
   - Y-axis: retention_rate_pct
   - Series: cohort_month (different cohorts as separate lines)

4. **day06_customer_health** ‚Üí Health Score Distribution
   - Pie chart: COUNT(*) GROUP BY health_status
   - Table: Top customers by ltv_cac_ratio
```

**Complexity Assessment:**
- **SQL Complexity:** M√©dia (CTEs, window functions, date calculations)
- **Business Logic:** Alta (SaaS metrics s√£o sutis - MRR movements, cohort logic)
- **Data Volume:** 500 customers, 24 months history (~6,000 subscription records)
- **Time Estimate:** 3h (mais tempo em business logic que c√≥digo)

**Final Validation:**
```sql
-- Run these queries to validate
SELECT * FROM day06_mrr_summary ORDER BY month;
SELECT * FROM day06_churn_by_cohort ORDER BY cohort_month, plan_tier;
SELECT * FROM day06_retention_curves WHERE cohort_month = '2024-01-01';
SELECT * FROM day06_customer_health WHERE health_status = 'Healthy';
-- Should return results with no errors and sensible values
```

**Naming Examples:**
```python
# ‚úÖ CORRECT
DAY06_DB_PATH = "data/day06_saas_metrics.db"
DAY06_DEFAULT_CAC = 500.0
DAY06_PLAN_TIERS = ['Starter', 'Pro', 'Enterprise']

class day06_SaasMetricsGenerator:
    pass

def day06_calculate_mrr_movement():
    pass

# ‚ùå WRONG - Generic names cause conflicts
DB_PATH = "data/database.db"  # Could conflict with other days
class MetricsGenerator:  # Too generic
```

---

### **Day 7 (Carol - Hospitality LTV & Cohort Model)**

**Data Sources:**
- Synthetic guest/booking data (pousada in Campos do Jord√£o)

**Mandatory Output:**
- [ ] SQLite database with `dayXX_guests`, `dayXX_bookings`, `dayXX_stays`
- [ ] Cohort table: Guests grouped by month of first reservation
- [ ] LTV by cohort (how much each cohort has spent to date)
- [ ] Retention matrix (% returning after 1, 3, 6, 12 months)
- [ ] Documented SQL queries
- [ ] Simple visualization prep (CSV or Looker Studio connection)

**When to Stop:**
- ‚úÖ Cohort table with at least 12 months of data
- ‚úÖ LTV calculated with window function (SUM OVER)
- ‚úÖ Retention matrix with at least 3 periods (1M, 3M, 6M)
- ‚úÖ README explains "How Carol uses this for retention strategy"
- ‚úÖ Obvious insights in data (e.g., "January cohort has 30% higher LTV")
- ‚ùå DON'T do: Churn prediction, real booking system integration, advanced segmentation

**Expected Files:**
```
dayXX/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ dayXX_hospitality.db
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ dayXX_MODEL_cohorts.sql
‚îÇ   ‚îî‚îÄ‚îÄ dayXX_MODEL_ltv.sql
‚îú‚îÄ‚îÄ dayXX_DATA_synthetic_guests.py
‚îú‚îÄ‚îÄ dayXX_CONFIG_settings.py
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

**Naming Examples:**
```sql
-- ‚úÖ CORRECT
CREATE TABLE dayXX_guest_cohorts AS ...
CREATE VIEW dayXX_ltv_analysis AS ...

-- ‚ùå WRONG
CREATE TABLE guest_cohorts AS ...  -- Too generic
```

**Cohort Query Example:**
```sql
-- dayXX_MODEL_cohorts.sql
WITH dayXX_first_booking AS (
    SELECT
        guest_id,
        MIN(booking_date) as first_booking_date,
        DATE_TRUNC('month', MIN(booking_date)) as cohort_month
    FROM dayXX_bookings
    GROUP BY guest_id
),
dayXX_cohort_ltv AS (
    SELECT
        fb.cohort_month,
        fb.guest_id,
        SUM(b.total_spend) OVER (
            PARTITION BY fb.guest_id
            ORDER BY b.booking_date
        ) as cumulative_ltv
    FROM dayXX_first_booking fb
    JOIN dayXX_bookings b ON fb.guest_id = b.guest_id
)
SELECT * FROM dayXX_cohort_ltv;
```

---

### **Day 8 (Patrick - SaaS Growth Funnel & Cohort Analysis with dbt)**

**Stakeholder:** Patrick (MBA, Strategy)

**Project:** SaaS Growth Funnel & Cohort Analysis (dbt)

**Focus:** Acquisition funnel, activation, engagement

**Data Sources:**
- Synthetic SaaS user events data (visits, signups, activations, subscriptions)
- 10K users, 100K events

**Mandatory Output:**
- [ ] dbt project with 5 core models:
```
  models/
    staging/
      stg_users.sql
      stg_events.sql
      stg_subscriptions.sql
      sources.yml
    intermediate/
      int_funnel_steps.sql
      int_user_engagement.sql
      int_feature_usage.sql
    marts/
      fct_acquisition_funnel.sql (incremental)
      fct_engagement_cohorts.sql
      dim_user_health.sql
```

**Core Deliverables:**

**dbt Models:**
1. **Acquisition Funnel** (Visit ‚Üí Signup ‚Üí Activation ‚Üí Paid)
2. **Engagement Cohorts** (DAU/WAU/MAU by cohort)
3. **Feature Adoption** (which features drive retention)
4. **Expansion Signals** (indicators for upsell)
5. **Activation Rate** (time to first value)

**Output Models (Ready for Dashboard):**
```sql
-- Model 1: Funnel Conversion
fct_acquisition_funnel
‚îú‚îÄ‚îÄ cohort_month
‚îú‚îÄ‚îÄ visitors
‚îú‚îÄ‚îÄ signups
‚îú‚îÄ‚îÄ activated
‚îú‚îÄ‚îÄ paid
‚îî‚îÄ‚îÄ conversion_rates

-- Model 2: Engagement by Cohort
fct_engagement_cohorts
‚îú‚îÄ‚îÄ cohort_month
‚îú‚îÄ‚îÄ months_since_signup
‚îú‚îÄ‚îÄ dau_rate
‚îú‚îÄ‚îÄ feature_adoption_rate
‚îî‚îÄ‚îÄ retention_rate
```

**When to Stop:**
- ‚úÖ dbt project runs with `dbt run` and `dbt test`
- ‚úÖ All 5 core models created and tested
- ‚úÖ Funnel stages clearly defined (Visit ‚Üí Signup ‚Üí Activation ‚Üí Paid)
- ‚úÖ Cohort analysis with engagement metrics (DAU/WAU/MAU)
- ‚úÖ Feature adoption tracking implemented
- ‚úÖ Incremental model working (`dbt run --full-refresh` vs. `dbt run`)
- ‚úÖ 5+ tests passing
- ‚úÖ README explains "How Patrick uses this for growth strategy"
- ‚úÖ **Dashboard Integration**: Documentation showing connection to Day 16 dashboard
- ‚úÖ **Architectural Decision**: "Why dbt + incremental models for funnel tracking?" documented
- ‚ùå DON'T do: Real-time processing, complex ML predictions, multi-product handling, advanced attribution, production deployment

**Expected Files:**
```
day08/
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_users.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_events.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_subscriptions.sql
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_funnel_steps.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_user_engagement.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_feature_usage.sql
‚îÇ   ‚îî‚îÄ‚îÄ marts/
‚îÇ       ‚îú‚îÄ‚îÄ fct_acquisition_funnel.sql (incremental)
‚îÇ       ‚îú‚îÄ‚îÄ fct_engagement_cohorts.sql
‚îÇ       ‚îî‚îÄ‚îÄ dim_user_health.sql
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îî‚îÄ‚îÄ calculate_activation_time.sql
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ schema.yml
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ day08_saas_funnel.db
‚îú‚îÄ‚îÄ day08_DATA_synthetic_generator.py
‚îú‚îÄ‚îÄ day08_CONFIG_settings.py
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

**dbt Naming Convention:**
```yaml
# In dbt_project.yml
name: 'day08_saas_funnel'
profile: 'day08_funnel'

# In models
models:
  day08_saas_funnel:
    staging:
      +materialized: view
    intermediate:
      +materialized: view
    marts:
      +materialized: table
```

**dbt Model Examples:**
```sql
-- models/staging/stg_users.sql
{{ config(materialized='view') }}

WITH source AS (
    SELECT * FROM {{ source('day08_saas', 'raw_users') }}
),

renamed AS (
    SELECT
        user_id AS day08_user_id,
        signup_date AS day08_signup_date,
        email AS day08_email,
        utm_source AS day08_utm_source,
        utm_campaign AS day08_utm_campaign
    FROM source
)

SELECT * FROM renamed
```

```sql
-- models/marts/fct_acquisition_funnel.sql (incremental)
{{
  config(
    materialized='incremental',
    unique_key='day08_cohort_month',
    on_schema_change='append_new_columns'
  )
}}

WITH funnel_stages AS (
    SELECT * FROM {{ ref('int_funnel_steps') }}
),

cohort_funnel AS (
    SELECT
        DATE_TRUNC('month', signup_date) as day08_cohort_month,
        COUNT(DISTINCT CASE WHEN stage = 'visit' THEN user_id END) as day08_visitors,
        COUNT(DISTINCT CASE WHEN stage = 'signup' THEN user_id END) as day08_signups,
        COUNT(DISTINCT CASE WHEN stage = 'activated' THEN user_id END) as day08_activated,
        COUNT(DISTINCT CASE WHEN stage = 'paid' THEN user_id END) as day08_paid
    FROM funnel_stages
    GROUP BY DATE_TRUNC('month', signup_date)
)

SELECT
    day08_cohort_month,
    day08_visitors,
    day08_signups,
    day08_activated,
    day08_paid,
    ROUND(100.0 * day08_signups / NULLIF(day08_visitors, 0), 2) as day08_visit_to_signup_rate,
    ROUND(100.0 * day08_activated / NULLIF(day08_signups, 0), 2) as day08_signup_to_activation_rate,
    ROUND(100.0 * day08_paid / NULLIF(day08_activated, 0), 2) as day08_activation_to_paid_rate
FROM cohort_funnel

{% if is_incremental() %}
  WHERE day08_cohort_month > (SELECT MAX(day08_cohort_month) FROM {{ this }})
{% endif %}
```

```sql
-- models/marts/fct_engagement_cohorts.sql
{{ config(materialized='table') }}

WITH user_cohorts AS (
    SELECT
        user_id,
        DATE_TRUNC('month', signup_date) as cohort_month
    FROM {{ ref('stg_users') }}
),

engagement_metrics AS (
    SELECT
        uc.cohort_month as day08_cohort_month,
        DATEDIFF(MONTH, uc.cohort_month, e.event_date) as day08_months_since_signup,
        COUNT(DISTINCT CASE WHEN e.event_type = 'daily_active' THEN e.user_id END) /
            NULLIF(COUNT(DISTINCT uc.user_id), 0) as day08_dau_rate,
        COUNT(DISTINCT CASE WHEN e.event_type = 'feature_used' THEN e.user_id END) /
            NULLIF(COUNT(DISTINCT uc.user_id), 0) as day08_feature_adoption_rate,
        COUNT(DISTINCT e.user_id) / NULLIF(COUNT(DISTINCT uc.user_id), 0) as day08_retention_rate
    FROM user_cohorts uc
    LEFT JOIN {{ ref('stg_events') }} e ON uc.user_id = e.user_id
    GROUP BY uc.cohort_month, DATEDIFF(MONTH, uc.cohort_month, e.event_date)
)

SELECT * FROM engagement_metrics
```

**dbt Tests Example:**
```yaml
# tests/schema.yml
version: 2

models:
  - name: stg_users
    columns:
      - name: day08_user_id
        tests:
          - unique
          - not_null
      - name: day08_signup_date
        tests:
          - not_null

  - name: stg_events
    columns:
      - name: day08_event_id
        tests:
          - unique
          - not_null
      - name: day08_user_id
        tests:
          - not_null
          - relationships:
              to: ref('stg_users')
              field: day08_user_id

  - name: fct_acquisition_funnel
    columns:
      - name: day08_cohort_month
        tests:
          - unique
          - not_null
      - name: day08_visitors
        tests:
          - not_null
```

**Dashboard Integration (Day 16):**
```markdown
## Connection to Day 16 Dashboard

The following models are designed to be consumed by the Dashboard project:

1. **fct_acquisition_funnel** ‚Üí Funnel Conversion Chart
   - X-axis: cohort_month
   - Y-axis: visitors, signups, activated, paid
   - Conversion rates displayed as annotations

2. **fct_engagement_cohorts** ‚Üí Engagement Trends
   - X-axis: months_since_signup
   - Y-axis: dau_rate, feature_adoption_rate, retention_rate
   - Series: cohort_month (different cohorts as separate lines)

3. **dim_user_health** ‚Üí User Health Segmentation
   - Pie chart: COUNT(*) GROUP BY health_status
   - Table: Top users by engagement score
```

**Complexity Assessment:**
- **dbt Complexity:** M√©dia (incremental models, macros)
- **Business Logic:** M√©dia (growth metrics, cohort analysis)
- **Data Volume:** 10K users, 100K events
- **Time Estimate:** 3h (dbt setup + models + documentation)

**Final Validation:**
```bash
# Run dbt commands
cd day08
dbt run --full-refresh
dbt test
dbt docs generate

# Validate results
sqlite3 data/day08_saas_funnel.db "SELECT * FROM fct_acquisition_funnel ORDER BY day08_cohort_month;"
sqlite3 data/day08_saas_funnel.db "SELECT * FROM fct_engagement_cohorts WHERE day08_cohort_month = '2024-01-01';"
```

**Naming Examples:**
```python
# ‚úÖ CORRECT
DAY08_DB_PATH = "data/day08_saas_funnel.db"
DAY08_ACTIVATION_THRESHOLD = 3  # days
DAY08_FUNNEL_STAGES = ['visit', 'signup', 'activated', 'paid']

class day08_SaasFunnelGenerator:
    pass

def day08_calculate_activation_rate():
    pass

# ‚ùå WRONG - Generic names cause conflicts
DB_PATH = "data/database.db"
class FunnelGenerator:  # Too generic
```

---

### **Day 9 (Jo - Property Manager Operations Data Warehouse with dbt)**

**Stakeholder:** Jo (Property Manager - 6 houseboats)

**Project:** Multi-Platform Property Management Data Warehouse Foundation

**Focus:** Unified operations funnel tracking across booking platforms (Airbnb + Booking.com), conversion optimization, and portfolio performance metrics

**Data Sources:**
- Synthetic multi-platform reservation data (Airbnb + Booking.com)
- Complete guest journey: Inquiry ‚Üí Booking ‚Üí Check-in ‚Üí Check-out ‚Üí Review
- 500+ reservations, 12+ months history

---

## üìã Public vs Private Deliverables

### **What Goes on GitHub (Public Portfolio)**
‚úÖ **Technical implementation** (dbt models, SQL, macros)
‚úÖ **Architecture documentation** (why dbt, why incremental models)
‚úÖ **Portfolio metrics** (presented as "demonstration of multi-platform data unification")
‚úÖ **Business problem framing** ("Property managers need unified analytics across platforms")
‚úÖ **How to run locally** (setup instructions, sample queries)
‚úÖ **Technical learning objectives** (dbt features demonstrated)

‚ùå **ANY mention of**: MicroSaaS, commercial plans, product roadmap, MVP, "Phase 1/2/3", business model, pricing, or competitive analysis

### **What Stays Local (Product Development)**
üìù **PRIVATE_PRODUCT_NOTES.md** (NOT in public repo):
- MicroSaaS vision and 3-phase roadmap
- Why this schema powers the commercial product
- Migration path from SQLite ‚Üí Supabase (production DB)
- Which tables power which SaaS features
- Competitive analysis vs. Guesty/Hostaway
- Technical debt and production hardening notes

üîí **Add to .gitignore**:
```
PRIVATE_PRODUCT_NOTES.md
MICROSAAS_ROADMAP.md
/business_plan/
/pricing_research/
/competitor_analysis/
*.private.*
```

---

## üìÑ Licensing Strategy

**Use MIT License with Commercial Use Restriction**

**Why this approach:**
- Shows confidence in code quality (industry-standard MIT base)
- Protects commercial opportunity (prevents direct cloning for profit)
- Allows educational/portfolio use (helps you get hired)
- Standard for "open core" SaaS models

**LICENSE file to include:**
```
MIT License (Modified for Portfolio Use)

Copyright (c) 2025 [Your Name]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to use,
copy, modify, merge, and distribute the Software for NON-COMMERCIAL purposes,
subject to the following conditions:

[Standard MIT License conditions...]

COMMERCIAL USE RESTRICTION:
Commercial use of this software (defined as use in a business, product, or
service that generates revenue) requires explicit written permission from
the copyright holder.

For portfolio/educational use: Freely available
For commercial licensing inquiries: [your contact email]
```

**Alternative:** Use "Commons Clause" addon to MIT for stronger protection

---

## üéØ Mandatory Output

**Core dbt Project Structure:**
- [ ] dbt project with production-ready architecture:
```
  models/
    staging/
      stg_airbnb_inquiries.sql
      stg_airbnb_bookings.sql
      stg_booking_com_inquiries.sql
      stg_booking_com_bookings.sql
      stg_stays.sql (unified across platforms)
      stg_reviews.sql (unified)
      sources.yml (with freshness tests)
    intermediate/
      int_unified_reservations.sql (platform unification logic)
      int_funnel_events.sql (all stages)
      int_property_performance.sql
    marts/
      fct_funnel_conversion.sql (incremental!)
      fct_reservations_unified.sql
      metrics_portfolio_public.sql (powers public-facing portfolio page)
      dim_platform_comparison.sql
```

**Critical Business Requirements:**
- [ ] **Multi-Platform Unification**: Airbnb + Booking.com data merged with platform tracking
- [ ] **Complete Operations Funnel**: Inquiry ‚Üí Booking ‚Üí Check-in ‚Üí Check-out ‚Üí Review
- [ ] **Portfolio Metrics Mart**: Occupancy rate, ADR (Average Daily Rate), RevPAR, platform mix
- [ ] **Conversion Metrics**: Stage-by-stage conversion rates, drop-off analysis, time-to-conversion
- [ ] **Incremental Processing**: Only new events processed (production-ready pattern)
- [ ] **Custom Business Logic Macros**: `calculate_stage_duration()`, `calculate_occupancy_rate()`, `unify_platform_data()`

---

## ‚è±Ô∏è When to Stop

### **Technical Completeness:**
- ‚úÖ Incremental model working (`dbt run --full-refresh` vs. `dbt run`)
- ‚úÖ At least 2 custom macros created and used (stage duration + one business logic macro)
- ‚úÖ Sources declared with freshness tests (both Airbnb + Booking.com sources)
- ‚úÖ Complete funnel with 5 stages (inquiry/booking/check-in/check-out/review)
- ‚úÖ Multi-platform unification logic working (Airbnb + Booking.com unified)
- ‚úÖ 5+ dbt tests passing (unique, not_null, relationships, custom)

### **Business Requirements Met:**
- ‚úÖ Portfolio metrics mart created (`metrics_portfolio_public.sql`)
- ‚úÖ Platform comparison dimension showing Airbnb vs Booking.com performance
- ‚úÖ Occupancy rate calculated correctly (nights booked / nights available)
- ‚úÖ ADR and RevPAR metrics accurate

### **Documentation Complete:**
- ‚úÖ **PUBLIC README** (portfolio-focused, no commercial mentions)
- ‚úÖ **PRIVATE_PRODUCT_NOTES.md** (strategic context for your eyes only)
- ‚úÖ **Architectural Decision**: "Why incremental models for operations data?" documented
- ‚úÖ **Architectural Decision**: "Multi-platform unification strategy" documented
- ‚úÖ Clear separation: Public vs Private documentation

### **What NOT to Build:**
- ‚ùå Real-time processing (batch is fine for portfolio)
- ‚ùå Complex orchestration (Airflow/Dagster)
- ‚ùå External API calls (use synthetic data)
- ‚ùå ML predictions (churn/pricing models)
- ‚ùå Production deployment (keep local SQLite for portfolio)
- ‚ùå Real booking platform integrations

---

## üìÅ Expected Files

```
day09/
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sources.yml (both platforms declared)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_airbnb_inquiries.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_airbnb_bookings.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_booking_com_inquiries.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_booking_com_bookings.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_stays.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_reviews.sql
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_unified_reservations.sql (‚òÖ CRITICAL: platform unification)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_funnel_events.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_property_performance.sql
‚îÇ   ‚îî‚îÄ‚îÄ marts/
‚îÇ       ‚îú‚îÄ‚îÄ fct_funnel_conversion.sql (incremental)
‚îÇ       ‚îú‚îÄ‚îÄ fct_reservations_unified.sql
‚îÇ       ‚îú‚îÄ‚îÄ metrics_portfolio_public.sql (‚òÖ CRITICAL: portfolio metrics)
‚îÇ       ‚îî‚îÄ‚îÄ dim_platform_comparison.sql
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îú‚îÄ‚îÄ calculate_stage_duration.sql
‚îÇ   ‚îú‚îÄ‚îÄ calculate_occupancy_rate.sql
‚îÇ   ‚îî‚îÄ‚îÄ unify_platform_data.sql
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ schema.yml (5+ tests)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ day09_property_operations.db
‚îú‚îÄ‚îÄ day09_DATA_synthetic_generator.py
‚îú‚îÄ‚îÄ day09_CONFIG_settings.py
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ LICENSE (MIT with commercial restriction)
‚îú‚îÄ‚îÄ README.md (PUBLIC - portfolio focus)
‚îî‚îÄ‚îÄ PRIVATE_PRODUCT_NOTES.md (LOCAL ONLY - not in git)
```

---

## üìñ Documentation Requirements

### **PUBLIC README Structure (day09/README.md)**

**Purpose:** Portfolio demonstration
**Audience:** Recruiters, hiring managers, data engineering community
**Tone:** Educational, technical, portfolio-focused

**Required Sections:**
```markdown
# Day 9: Multi-Platform Property Management Data Warehouse

## Business Problem
Independent property managers use multiple booking platforms (Airbnb, Booking.com)
but lack unified analytics. This project demonstrates data unification techniques
and dbt best practices for building a production-ready data warehouse.

## Technical Architecture
[Explain dbt project structure, incremental models, multi-platform unification strategy]

## Key Features Demonstrated
- Multi-source data integration (Airbnb + Booking.com)
- Incremental processing for efficient updates
- Custom business logic macros (occupancy, ADR, stage duration)
- Source freshness monitoring
- Comprehensive dbt testing strategy

## Data Models

### Staging Layer
[Describe source declarations and initial transformations]

### Intermediate Layer
[Explain platform unification logic]

### Marts Layer
[Document final business-ready models]

## Metrics Delivered
- Occupancy Rate (nights booked / nights available)
- Average Daily Rate (ADR)
- Revenue Per Available Room (RevPAR)
- Funnel conversion rates (inquiry ‚Üí review)
- Platform performance comparison

## How to Run Locally
[Step-by-step setup instructions]

## Architecture Decisions

### Why Incremental Models?
[Explain: production-ready pattern, efficient processing, scalable]

### Multi-Platform Unification Strategy
[Explain: common schema, platform tracking, unified metrics]

## Learning Outcomes
- dbt project architecture
- Incremental materialization patterns
- Custom macro development
- Multi-source data integration
- Hospitality industry metrics

---
Built as part of a 25-day data engineering portfolio project
```

**‚ùå DO NOT INCLUDE in Public README:**
- MicroSaaS vision or product plans
- Commercial opportunity mentions
- MVP or "Phase 1/2/3" language
- Pricing model considerations
- Competitive analysis (Guesty/Hostaway)
- Production migration plans (SQLite ‚Üí Supabase)

---

### **PRIVATE PRODUCT NOTES Structure (day09/PRIVATE_PRODUCT_NOTES.md)**

**Purpose:** Internal product development documentation
**Audience:** Only you (and future co-founders/investors)
**Location:** Keep local, add to .gitignore

**Required Sections:**
```markdown
# Day 9: Property Manager Data Warehouse - Product Context

## MicroSaaS Vision (CONFIDENTIAL)

### Target Market
- Independent property managers (1-15 properties)
- Currently underserved by enterprise PMS (Guesty charges $30-50/property/month)
- Need unified analytics across Airbnb + Booking.com
- Jo (6 houseboats) = first real user / design partner

### Product Roadmap
**Phase 1 (MVP):** Portfolio Builder
- Public-facing property showcase page
- Unified availability calendar
- Performance metrics dashboard
- Powered by: metrics_portfolio_public.sql

**Phase 2:** Direct Booking Engine
- iCal sync with Airbnb/Booking.com
- Direct booking flow (bypass platform fees)
- Payment processing integration

**Phase 3:** Operations Automation
- Automated guest messages
- Cleaning/maintenance scheduling
- Dynamic pricing suggestions

### How This dbt Project Supports the SaaS

#### Tables ‚Üí SaaS Features Mapping
- `fct_reservations_unified` ‚Üí Calendar sync + availability management
- `metrics_portfolio_public` ‚Üí Public portfolio page (Phase 1 MVP)
- `dim_platform_comparison` ‚Üí Platform performance analytics
- `fct_funnel_conversion` ‚Üí Conversion optimization insights

#### Production Migration Path
- **Current:** SQLite (portfolio demonstration)
- **Phase 1 Production:** Supabase (Postgres + Auth + Storage)
- **Migration Strategy:** dbt profiles.yml switch, no code changes needed
- **Timeline:** 2 days after first paying customer

### Competitive Analysis
**vs. Guesty ($30-50/property/month):**
- Guesty: Enterprise-focused, complex, expensive for small operators
- Us: Lightweight, affordable ($10-15/property/month), independent-host-focused

**vs. Hostaway ($25-35/property/month):**
- Hostaway: Good mid-market option, still pricey for 1-10 properties
- Us: Better pricing for micro-operators, simpler UX

### Technical Debt / Production Hardening Needed
- [ ] Add proper error handling in dbt models
- [ ] Implement data quality monitoring (Great Expectations)
- [ ] Add CI/CD for dbt runs (GitHub Actions)
- [ ] Set up incremental backfill strategy
- [ ] Migrate from SQLite to Supabase
- [ ] Add multi-tenancy (property_manager_id in all tables)
- [ ] Implement RBAC (owner vs guest access)

### Pricing Model (Initial Thinking)
- $10/property/month (base tier - analytics only)
- $15/property/month (pro tier - direct booking)
- $20/property/month (automation tier - messages/scheduling)
- Target: 100 properties by Month 6 = $1-2K MRR

### Next Steps After Portfolio Delivery
1. User interview with Jo (validate metrics, get feedback)
2. Design Figma mockups for portfolio page
3. Set up Supabase project
4. Migrate dbt to Supabase profiles
5. Build Next.js frontend for Phase 1 MVP
```

**üîí CRITICAL:** This file NEVER goes on GitHub. Keep local only.

---

## üíª Code Examples

### **dbt Project Configuration**

```yaml
# dbt_project.yml
name: 'day09_property_ops'
profile: 'day09_property_ops'
version: '1.0.0'

models:
  day09_property_ops:
    staging:
      +materialized: view
      +tags: ['staging']
    intermediate:
      +materialized: view
      +tags: ['intermediate']
    marts:
      +materialized: table
      +tags: ['marts']
      fct_funnel_conversion:
        +materialized: incremental
        +unique_key: 'day09_event_id'
```

---

### **Staging: Multi-Platform Sources**

```yaml
# models/staging/sources.yml
version: 2

sources:
  - name: day09_airbnb
    database: day09_property_operations
    schema: raw
    tables:
      - name: airbnb_inquiries
        freshness:
          warn_after: {count: 12, period: hour}
          error_after: {count: 24, period: hour}
      - name: airbnb_bookings
        freshness:
          warn_after: {count: 6, period: hour}
          error_after: {count: 12, period: hour}

  - name: day09_booking_com
    database: day09_property_operations
    schema: raw
    tables:
      - name: booking_com_inquiries
        freshness:
          warn_after: {count: 12, period: hour}
      - name: booking_com_bookings
        freshness:
          warn_after: {count: 6, period: hour}

  - name: day09_operations
    database: day09_property_operations
    schema: raw
    tables:
      - name: stays
      - name: reviews
```

```sql
-- models/staging/stg_airbnb_inquiries.sql
{{ config(materialized='view') }}

WITH source AS (
    SELECT * FROM {{ source('day09_airbnb', 'airbnb_inquiries') }}
),

renamed AS (
    SELECT
        inquiry_id AS day09_inquiry_id,
        'airbnb' AS day09_platform,
        guest_id AS day09_guest_id,
        property_id AS day09_property_id,
        inquiry_timestamp AS day09_inquiry_timestamp,
        check_in_date AS day09_check_in_date,
        check_out_date AS day09_check_out_date,
        num_guests AS day09_num_guests,
        status AS day09_status
    FROM source
)

SELECT * FROM renamed
```

```sql
-- models/staging/stg_booking_com_inquiries.sql
{{ config(materialized='view') }}

WITH source AS (
    SELECT * FROM {{ source('day09_booking_com', 'booking_com_inquiries') }}
),

renamed AS (
    SELECT
        reservation_inquiry_id AS day09_inquiry_id,
        'booking_com' AS day09_platform,
        guest_email AS day09_guest_id,  -- Unification: use email as guest_id
        property_code AS day09_property_id,
        created_at AS day09_inquiry_timestamp,
        arrival_date AS day09_check_in_date,
        departure_date AS day09_check_out_date,
        guest_count AS day09_num_guests,
        inquiry_status AS day09_status
    FROM source
)

SELECT * FROM renamed
```

---

### **Intermediate: Platform Unification**

```sql
-- models/intermediate/int_unified_reservations.sql
{{ config(materialized='view') }}

WITH airbnb AS (
    SELECT * FROM {{ ref('stg_airbnb_bookings') }}
),

booking_com AS (
    SELECT * FROM {{ ref('stg_booking_com_bookings') }}
),

unified AS (
    SELECT
        day09_booking_id,
        day09_platform,
        day09_guest_id,
        day09_property_id,
        day09_check_in_date,
        day09_check_out_date,
        day09_num_guests,
        day09_total_price,
        day09_platform_fee,
        day09_net_revenue,
        day09_booking_timestamp,
        day09_status
    FROM airbnb

    UNION ALL

    SELECT
        day09_booking_id,
        day09_platform,
        day09_guest_id,
        day09_property_id,
        day09_check_in_date,
        day09_check_out_date,
        day09_num_guests,
        day09_total_price,
        day09_platform_fee,
        day09_net_revenue,
        day09_booking_timestamp,
        day09_status
    FROM booking_com
)

SELECT
    *,
    DATEDIFF(day, day09_check_in_date, day09_check_out_date) AS day09_nights,
    day09_total_price / NULLIF(DATEDIFF(day, day09_check_in_date, day09_check_out_date), 0) AS day09_adr
FROM unified
```

---

### **Marts: Incremental Funnel Conversion**

```sql
-- models/marts/fct_funnel_conversion.sql
{{
  config(
    materialized='incremental',
    unique_key='day09_event_id',
    on_schema_change='append_new_columns'
  )
}}

WITH funnel_events AS (
    SELECT * FROM {{ ref('int_funnel_events') }}
)

SELECT
    day09_event_id,
    day09_guest_id,
    day09_property_id,
    day09_platform,
    day09_stage,
    day09_event_timestamp,
    {{ calculate_stage_duration('day09_event_timestamp', 'day09_stage', 'day09_guest_id') }} AS day09_time_in_stage_hours,
    day09_converted_to_next_stage,
    day09_final_booking_value
FROM funnel_events

{% if is_incremental() %}
  WHERE day09_event_timestamp > (SELECT MAX(day09_event_timestamp) FROM {{ this }})
{% endif %}
```

---

### **Marts: Portfolio Metrics (Powers Public Page)**

```sql
-- models/marts/metrics_portfolio_public.sql
{{ config(materialized='table') }}

WITH reservations AS (
    SELECT * FROM {{ ref('fct_reservations_unified') }}
),

property_nights AS (
    SELECT
        day09_property_id,
        COUNT(*) AS day09_total_nights_booked,
        SUM(day09_total_price) AS day09_total_revenue,
        SUM(day09_net_revenue) AS day09_total_net_revenue,
        AVG(day09_adr) AS day09_avg_daily_rate
    FROM reservations
    WHERE day09_status = 'completed'
    GROUP BY day09_property_id
),

-- Calculate available nights (365 days per property for portfolio demo)
property_metrics AS (
    SELECT
        pn.day09_property_id,
        pn.day09_total_nights_booked,
        365 AS day09_nights_available,  -- Simplified for portfolio
        ROUND(100.0 * pn.day09_total_nights_booked / 365, 2) AS day09_occupancy_rate_pct,
        pn.day09_avg_daily_rate,
        ROUND(pn.day09_avg_daily_rate * (pn.day09_total_nights_booked / 365.0), 2) AS day09_revpar,
        pn.day09_total_revenue,
        pn.day09_total_net_revenue
    FROM property_nights pn
)

SELECT * FROM property_metrics
```

---

### **Custom Macros**

```sql
-- macros/calculate_stage_duration.sql
{% macro calculate_stage_duration(timestamp_col, stage_col, partition_col) %}
    TIMESTAMPDIFF(
        HOUR,
        LAG({{ timestamp_col }}) OVER (
            PARTITION BY {{ partition_col }}, {{ stage_col }}
            ORDER BY {{ timestamp_col }}
        ),
        {{ timestamp_col }}
    )
{% endmacro %}
```

```sql
-- macros/calculate_occupancy_rate.sql
{% macro calculate_occupancy_rate(nights_booked_col, nights_available_col) %}
    ROUND(100.0 * {{ nights_booked_col }} / NULLIF({{ nights_available_col }}, 0), 2)
{% endmacro %}
```

```sql
-- macros/unify_platform_data.sql
{% macro unify_platform_data(airbnb_col, booking_com_col, airbnb_default, booking_com_default) %}
    CASE
        WHEN platform = 'airbnb' THEN COALESCE({{ airbnb_col }}, {{ airbnb_default }})
        WHEN platform = 'booking_com' THEN COALESCE({{ booking_com_col }}, {{ booking_com_default }})
        ELSE NULL
    END
{% endmacro %}
```

---

### **dbt Tests**

```yaml
# tests/schema.yml
version: 2

models:
  - name: stg_airbnb_inquiries
    columns:
      - name: day09_inquiry_id
        tests:
          - unique
          - not_null
      - name: day09_platform
        tests:
          - accepted_values:
              values: ['airbnb', 'booking_com']

  - name: fct_reservations_unified
    columns:
      - name: day09_booking_id
        tests:
          - unique
          - not_null
      - name: day09_property_id
        tests:
          - not_null
      - name: day09_platform
        tests:
          - accepted_values:
              values: ['airbnb', 'booking_com']
      - name: day09_adr
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "> 0"

  - name: metrics_portfolio_public
    columns:
      - name: day09_property_id
        tests:
          - unique
          - not_null
      - name: day09_occupancy_rate_pct
        tests:
          - not_null
          - dbt_utils.expression_is_true:
              expression: "BETWEEN 0 AND 100"
```

---

## üéØ Complexity Assessment

- **dbt Complexity:** High (incremental models, multi-source unification, custom macros)
- **Business Logic:** High (hospitality metrics, multi-platform reconciliation)
- **Data Volume:** 500+ reservations, 12 months history, 2 platforms
- **Time Estimate:** 3h (dbt setup 30min, models 90min, testing/docs 60min)

---

## ‚úÖ Final Validation

```bash
# Navigate to project
cd day09

# Full refresh (builds from scratch)
dbt run --full-refresh

# Incremental run (only new data)
dbt run

# Run tests
dbt test

# Generate documentation
dbt docs generate
dbt docs serve

# Validate key metrics
sqlite3 data/day09_property_operations.db "SELECT * FROM metrics_portfolio_public;"
sqlite3 data/day09_property_operations.db "SELECT * FROM fct_funnel_conversion ORDER BY day09_event_timestamp DESC LIMIT 10;"
```

**Success Criteria:**
- ‚úÖ All dbt models run without errors
- ‚úÖ Incremental model only processes new events on second run
- ‚úÖ Occupancy rates between 0-100%
- ‚úÖ ADR and RevPAR values are realistic ($50-300/night range)
- ‚úÖ Platform unification works (Airbnb + Booking.com in same tables)
- ‚úÖ 5+ tests passing
- ‚úÖ Public README is portfolio-focused (no commercial mentions)
- ‚úÖ Private notes contain strategic context
- ‚úÖ LICENSE file included with commercial restriction

---

## üîê Pre-Commit Checklist

**Before pushing to GitHub:**
- [ ] `PRIVATE_PRODUCT_NOTES.md` is in `.gitignore`
- [ ] No mentions of "MicroSaaS", "MVP", "product roadmap" in public README
- [ ] LICENSE file includes commercial use restriction
- [ ] All code uses `day09_` prefix consistently
- [ ] dbt docs generated and models documented
- [ ] Tests passing (`dbt test`)
- [ ] Public README focuses on portfolio/learning objectives only
- [ ] No business model, pricing, or competitive analysis in public files

---

## üìä Naming Examples

```python
# ‚úÖ CORRECT
DAY09_DB_PATH = "data/day09_property_operations.db"
DAY09_PLATFORMS = ['airbnb', 'booking_com']
DAY09_FUNNEL_STAGES = ['inquiry', 'booking', 'check_in', 'check_out', 'review']

class day09_PropertyDataGenerator:
    pass

def day09_calculate_occupancy_rate():
    pass

# ‚ùå WRONG - Generic names cause conflicts
DB_PATH = "data/database.db"
class PropertyGenerator:  # Too generic
```

```sql
-- ‚úÖ CORRECT (dbt models)
CREATE VIEW day09_stg_airbnb_inquiries AS ...
CREATE TABLE day09_fct_reservations_unified AS ...

-- ‚ùå WRONG
CREATE VIEW stg_inquiries AS ...  -- Too generic
```

---

# PROJETO DAY 10: FAMILY OFFICE DATA WAREHOUSE (RAFAEL)

## CONTEXTO
Rafael √© especialista em cross-border wealth planning. Este projeto demonstra arquitetura de dados para family offices que gerenciam patrim√¥nio multi-jurisdicional.

**CRITICAL:** Uma das fam√≠lias no portf√≥lio possui uma manufacturing company europeia. Os ativos operacionais dessa empresa (equipamentos, IPs, certifica√ß√µes) ser√£o reutilizados no Day 16 (dashboard de compliance para Luna).

## MANDATORY OUTPUTS

### 1. KIMBALL STAR SCHEMA
```sql
-- Fact Table
CREATE TABLE fct_holdings (
    holding_key INTEGER PRIMARY KEY,
    client_key INTEGER,
    asset_key INTEGER,
    account_key INTEGER,
    date_key INTEGER,
    quantity DECIMAL(18,4),
    market_value DECIMAL(18,2),
    cost_basis DECIMAL(18,2)
);

-- Dimensions
CREATE TABLE dim_clients (
    client_key INTEGER PRIMARY KEY,
    client_id VARCHAR(50),
    client_name VARCHAR(200),
    client_type VARCHAR(50)
);

CREATE TABLE dim_assets (
    asset_key INTEGER PRIMARY KEY,
    asset_id VARCHAR(50),
    asset_name VARCHAR(200),
    asset_class VARCHAR(50),  -- 'Equity', 'Equipment', 'IP', 'Certification'
    asset_type VARCHAR(50),
    valid_from DATE,
    valid_to DATE,
    is_current BOOLEAN
);

CREATE TABLE dim_accounts (
    account_key INTEGER PRIMARY KEY,
    account_id VARCHAR(50),
    account_name VARCHAR(200),
    account_type VARCHAR(50),
    parent_client_key INTEGER
);

CREATE TABLE dim_date (
    date_key INTEGER PRIMARY KEY,
    full_date DATE,
    year INTEGER,
    quarter INTEGER,
    month INTEGER,
    fiscal_quarter INTEGER,
    fiscal_year INTEGER
);
```

### 2. SYNTHETIC DATA - DISTRIBUTION

**5 Families (Clients):**
1. Smith Family - traditional investments
2. Johnson Family - real estate focus
3. **MFG Owner Family** ‚Üê THIS ONE! Owns European manufacturing company
4. Lee Family - tech investments
5. Garcia Family - diversified

**100 Total Assets:**
- 50 financial assets (stocks, bonds, funds) - distributed across all families
- 20 operating company stakes
- **30 MFG Company operational assets (CRITICAL FOR DAY 16):**
  * **10 Equipment:**
    - EQ_MFG_001: "CNC Machine Haas VF-2" (UK, ‚Ç¨85k)
    - EQ_MFG_002: "3D Printer HP Multi Jet" (Netherlands, ‚Ç¨120k)
    - EQ_MFG_003: "Injection Molding Machine" (Germany, ‚Ç¨200k)
    - EQ_MFG_004-010: Similar industrial equipment across EMEA
  * **10 IP Assets:**
    - IP_MFG_001: "Patent EP12345 - Rapid Tooling Method" (‚Ç¨500k)
    - IP_MFG_002: "Trademark MFG QuickFab" (‚Ç¨50k)
    - IP_MFG_003-010: Patents, trademarks across EU jurisdictions
  * **10 Certifications:**
    - CERT_MFG_001: "CE Marking - Product Line A" (‚Ç¨10k)
    - CERT_MFG_002: "ISO 9001 - UK Facility" (‚Ç¨15k)
    - CERT_MFG_003: "REACH Compliance - DE Operations" (‚Ç¨8k)
    - CERT_MFG_004-010: Various regulatory certifications

**Accounts:**
- Each family has 2-3 accounts
- **MFG Owner Family must have:** "MFG Company Operating Account"

**Time Range:** 24 months of holdings data

### 3. SCD TYPE 2 - REQUIRED EXAMPLES

Demonstrate SCD Type 2 with at least 2 historical changes:

**Example 1: Asset reclassification**
```sql
-- Equipment lifecycle change
asset_key | asset_id    | asset_name         | asset_class  | valid_from | valid_to   | is_current
----------|-------------|--------------------|--------------|------------|------------|------------
1         | EQ_MFG_001  | "CNC Machine..."   | "Active"     | 2023-01-01 | 2024-06-30 | FALSE
2         | EQ_MFG_001  | "CNC Machine..."   | "Maintenance"| 2024-07-01 | 2024-09-30 | FALSE
3         | EQ_MFG_001  | "CNC Machine..."   | "Active"     | 2024-10-01 | NULL       | TRUE
```

**Example 2: Regulatory change**
```sql
-- Certification renewal/update
asset_key | asset_id      | asset_name      | requirements      | valid_from | valid_to   | is_current
----------|---------------|-----------------|-------------------|------------|------------|------------
10        | CERT_MFG_001  | "CE Marking..." | "Standard v1.0"   | 2023-01-01 | 2024-12-31 | FALSE
11        | CERT_MFG_001  | "CE Marking..." | "Standard v2.0"   | 2025-01-01 | NULL       | TRUE
```

### 4. ANALYTICAL QUERIES (4 REQUIRED)

**Query 1:** Total portfolio value per client
**Query 2:** Asset allocation by class (show Equipment, IP, Certification separately)
**Query 3:** **MFG Company assets only (CRITICAL - this will be reused in Day 16!)**
```sql
-- Filter for Luna's future dashboard
SELECT
    a.asset_name,
    a.asset_class,
    a.asset_type,
    h.market_value,
    acc.account_name
FROM fct_holdings h
JOIN dim_assets a ON h.asset_key = a.asset_key
JOIN dim_accounts acc ON h.account_key = acc.account_key
JOIN dim_clients c ON acc.parent_client_key = c.client_key
WHERE c.client_name = 'MFG Owner Family'
  AND a.asset_class IN ('Equipment', 'IP', 'Certification')
  AND h.date_key = (SELECT MAX(date_key) FROM dim_date);
```
**Query 4:** Historical tracking (SCD Type 2 demo)

### 5. FOLDER STRUCTURE
```
day10/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ day10_family_office_dw.db
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ day10_MODEL_star_schema.sql
‚îÇ   ‚îú‚îÄ‚îÄ day10_MODEL_dim_assets_scd2.sql
‚îÇ   ‚îî‚îÄ‚îÄ day10_MODEL_fact_holdings.sql
‚îú‚îÄ‚îÄ queries/
‚îÇ   ‚îú‚îÄ‚îÄ day10_QUERY_portfolio_value.sql
‚îÇ   ‚îú‚îÄ‚îÄ day10_QUERY_asset_allocation.sql
‚îÇ   ‚îú‚îÄ‚îÄ day10_QUERY_mfg_assets_filter.sql ‚Üê CRITICAL FOR DAY 16
‚îÇ   ‚îî‚îÄ‚îÄ day10_QUERY_historical_tracking.sql
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ day10_ERD_star_schema.md
‚îú‚îÄ‚îÄ day10_DATA_synthetic_generator.py
‚îî‚îÄ‚îÄ README.md
```

### 6. README STRUCTURE
```markdown
# Family Office Asset Management Data Warehouse

‚ö†Ô∏è **DISCLAIMER:** Educational portfolio project with 100% synthetic data. Inspired by conversations with Rafael (cross-border wealth planning specialist) but does not represent any real system.

## Problem Statement
Family offices managing multi-jurisdictional UHNW portfolios face challenges tracking assets across borders, tax treatments, and regulatory changes.

## Solution Architecture
Kimball star schema with SCD Type 2 for historical compliance.

## Use Case (Fictional)
5 UHNW families, 100+ assets, one family owns a European manufacturing company (operational assets will be analyzed separately in Day 16).

## What This Demonstrates
- Dimensional modeling for wealth structures
- SCD Type 2 for audit trails
- Conformed dimensions (preparing for Day 16 reuse)
- Cross-border asset tracking

## For Rafael
Technical demonstration of architectural patterns for complex wealth management. Focus on cross-border tracking and historical compliance.

**Note:** Day 16 will create a compliance dashboard consuming these MFG operational assets.
```

## QUANDO PARAR
‚úÖ Star schema with 5 tables implemented
‚úÖ 5 families, 100 assets (30 MFG operational assets clearly labeled)
‚úÖ SCD Type 2 with 2+ examples
‚úÖ 24 months of holdings data
‚úÖ 4 analytical queries (including MFG filter query)
‚úÖ ERD documented
‚úÖ README with disclaimer and Day 16 connection note
‚ùå DON'T: Real-time tracking, Bloomberg integration, IRR calculations, tax optimization

## ARCHITECTURAL NOTES TO DOCUMENT
1. Why Kimball? (Performance for cross-family analysis)
2. Why SCD Type 2? (Audit trails: "What was the classification on [date]?")
3. Why include operational assets in family office DW? (Consolidated wealth view + prepares for departmental analytics)
4. Conformed dimensions strategy: dim_date, dim_assets will be reused in Day 16

## SUCCESS CRITERIA
- Can answer: "Total portfolio value for MFG Owner Family?"
- Can answer: "What was EQ_MFG_001 classification on June 15, 2024?"
- Can filter ONLY MFG operational assets (Equipment, IP, Certification)
- Database ready to be consumed by Day 16 dashboard

**Gere o projeto completo priorizando CLAREZA na identifica√ß√£o dos MFG assets.**

**O que garante que Luna vai poder usar:**
‚úÖ 30 MFG assets claramente identificados (EQ_MFG_*, IP_MFG_*, CERT_MFG_*)
‚úÖ Query espec√≠fica j√° pronta (day10_QUERY_mfg_assets_filter.sql)
‚úÖ Account espec√≠fico: "MFG Company Operating Account"
‚úÖ Client espec√≠fico: "MFG Owner Family"
‚úÖ README menciona explicitamente: "Day 16 will reuse these assets"

---

## üîÑ PIVOT RULE (1 hour)

**For all Modeling projects:**

If after **1 hour** you still haven't:
- Set up the database/dbt environment OR
- Written basic working SQL

‚û°Ô∏è **IMMEDIATE PIVOT to simpler approach:**

1. Use SQLite instead of PostgreSQL/BigQuery
2. Use plain SQL instead of dbt (can migrate later)
3. Reduce number of metrics/dimensions
4. Focus on ONE core feature working perfectly

**DON'T spend more than 1h fighting with setup. The goal is to deliver, not perfectionism.**

**Example Pivot Scenarios:**

**Day 8/9 (dbt projects):**
```bash
# After 1h, if dbt setup still failing:

# BEFORE (complex):
dbt init dayXX_project
# ... 30 minutes of config errors ...

# AFTER (simple pivot):
# Create plain SQL files in models/ folder
# Run directly with sqlite3 or python
# Document: "Will migrate to dbt after proof of concept works"
```

**Day 10 (Data Warehouse):**
```bash
# After 1h, if SCD Type 2 logic too complex:

# BEFORE (full SCD Type 2):
# Trying to implement merge/upsert logic with triggers...

# AFTER (simple pivot):
# Create basic dimension table (no SCD)
# Add is_current flag manually
# Document: "Simplified SCD Type 2 - full implementation in production phase"
```

---

## üìä FINAL VALIDATION (All Projects)

Before pushing:
```bash
# 1. Test in clean environment
cd /tmp
git clone your-repo
cd advent-automation-2025/dayXX

# 2. Configure .env (add project variables to root config/.env)
# Make sure to follow convention: DAYXX_SPECIFIC_VAR

# 3. Execute
python dayXX_DATA_synthetic_generator.py  # Generate data
sqlite3 data/dayXX_database.db < models/dayXX_MODEL_*.sql  # Run models
# OR
cd dayXX && dbt run && dbt test  # If using dbt

# 4. Validate
# - Models executed without errors? ‚úÖ
# - Results make business sense? ‚úÖ
# - Logs are informative? ‚úÖ
# - Naming convention correct (dayXX_ prefix)? ‚úÖ
```

If ALL above works ‚Üí ‚úÖ **Project complete**

---

## üîß INTEGRATION WITH EXISTING STRUCTURE CHECKLIST

Before finalizing any Modeling project, verify:

- [ ] Environment variables added to `config/.env` following existing convention
- [ ] Specific dependencies documented in `dayXX_requirements.txt` (if needed)
- [ ] Common dependencies added to root `requirements.txt` (only if globally relevant)
- [ ] ALL files have `dayXX_` prefix
- [ ] ALL variables/classes/functions follow isolated naming
- [ ] README clearly explains how to configure environment variables
- [ ] Project works INDEPENDENTLY (doesn't depend on other days)

**Environment Variables Example:**
```bash
# In root config/.env

# Day 06 - Financial Consulting Metrics
DAYXX_DB_PATH=/path/to/dayXX_consulting.db
DAYXX_LOOKER_STUDIO_ID=abc123

# Day 07 - Hospitality LTV
DAYXX_HOSPITALITY_DB_PATH=/path/to/dayXX_hospitality.db

# Day 08 - Consulting Pipeline (dbt)
DAYXX_DBT_PROFILES_DIR=/path/to/dayXX/.dbt

# Day 09 - Hospitality Funnel (dbt)
DAYXX_DBT_TARGET=dev

# Day 10 - Family Office DW
DAYXX_DW_DB_PATH=/path/to/dayXX_family_office_dw.db
```

**Dependencies Example:**
```txt
# In root requirements.txt

# Day 06-07: SQL + Analytics
sqlalchemy==2.0.23
pandas==2.1.4

# Day 08-09: dbt
dbt-core==1.7.4
dbt-sqlite==1.7.1

# Day 10: Data Warehouse
sqlalchemy==2.0.23
```

---

## üí° FINAL REMINDER

**You're building a PORTFOLIO, not a production product.**

The goal is to demonstrate:
- ‚úÖ You know data modeling concepts
- ‚úÖ You know SQL (CTEs, window functions, joins)
- ‚úÖ You understand business logic translation
- ‚úÖ You can document your work
- ‚úÖ You can deliver in 3 hours
- ‚úÖ You know how to work with code isolation

**NOT to demonstrate:**
- ‚ùå Perfect, bug-free system
- ‚ùå Optimized performance
- ‚ùå All edge cases handled
- ‚ùå Production-ready code

**Focus: Functional > Perfect. Documented > Complex. Delivered > Ideal. Isolated > Shared.**

---

## üìö QUICK REFERENCE - SQL PATTERNS

### **CTEs (Common Table Expressions)**
```sql
-- Basic CTE
WITH dayXX_metrics AS (
    SELECT
        project_id,
        SUM(hours) as total_hours
    FROM dayXX_timesheets
    GROUP BY project_id
)
SELECT * FROM dayXX_metrics;

-- Multiple CTEs
WITH dayXX_billable AS (
    SELECT project_id, SUM(hours) as billable_hours
    FROM dayXX_timesheets
    WHERE is_billable = TRUE
    GROUP BY project_id
),
dayXX_total AS (
    SELECT project_id, SUM(hours) as total_hours
    FROM dayXX_timesheets
    GROUP BY project_id
)
SELECT
    b.project_id,
    b.billable_hours,
    t.total_hours,
    ROUND(100.0 * b.billable_hours / t.total_hours, 2) as utilization_rate
FROM dayXX_billable b
JOIN dayXX_total t ON b.project_id = t.project_id;
```

### **Window Functions**
```sql
-- Running totals
SELECT
    date,
    revenue,
    SUM(revenue) OVER (ORDER BY date) as cumulative_revenue
FROM dayXX_sales;

-- Ranking
SELECT
    project_name,
    profitability,
    RANK() OVER (ORDER BY profitability DESC) as profitability_rank
FROM dayXX_projects;

-- Lag/Lead (comparing to previous period)
SELECT
    date,
    revenue,
    LAG(revenue) OVER (ORDER BY date) as previous_month_revenue,
    revenue - LAG(revenue) OVER (ORDER BY date) as revenue_change
FROM dayXX_monthly_sales;

-- Partition by
SELECT
    client_id,
    project_id,
    revenue,
    SUM(revenue) OVER (PARTITION BY client_id) as client_total_revenue,
    ROUND(100.0 * revenue / SUM(revenue) OVER (PARTITION BY client_id), 2) as pct_of_client_revenue
FROM dayXX_projects;
```

### **Cohort Analysis Pattern**
```sql
-- Step 1: Identify first event per user
WITH dayXX_first_event AS (
    SELECT
        user_id,
        MIN(event_date) as first_event_date,
        DATE_TRUNC('month', MIN(event_date)) as cohort_month
    FROM dayXX_events
    GROUP BY user_id
),

-- Step 2: Calculate time since first event
dayXX_cohort_activity AS (
    SELECT
        fe.cohort_month,
        fe.user_id,
        e.event_date,
        DATEDIFF(MONTH, fe.first_event_date, e.event_date) as months_since_first
    FROM dayXX_first_event fe
    JOIN dayXX_events e ON fe.user_id = e.user_id
),

-- Step 3: Calculate retention
dayXX_retention AS (
    SELECT
        cohort_month,
        months_since_first,
        COUNT(DISTINCT user_id) as active_users
    FROM dayXX_cohort_activity
    GROUP BY cohort_month, months_since_first
)

-- Step 4: Calculate retention rate
SELECT
    r.cohort_month,
    r.months_since_first,
    r.active_users,
    first.cohort_size,
    ROUND(100.0 * r.active_users / first.cohort_size, 2) as retention_rate
FROM dayXX_retention r
JOIN (
    SELECT cohort_month, active_users as cohort_size
    FROM dayXX_retention
    WHERE months_since_first = 0
) first ON r.cohort_month = first.cohort_month
ORDER BY r.cohort_month, r.months_since_first;
```

---

## üéì LEARNING RESOURCES (Optional - After 3h)

If you finish early or want to learn more AFTER the 3-hour delivery:

### **SQL & Data Modeling:**
- [SQL Window Functions Tutorial](https://mode.com/sql-tutorial/sql-window-functions/)
- [Kimball Star Schema Guide](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/)
- [Cohort Analysis SQL](https://sqlsandwich.com/blog/cohort-analysis-sql/)

### **dbt:**
- [dbt Official Docs](https://docs.getdbt.com/)
- [dbt Learn - Free Courses](https://learn.getdbt.com/)
- [Incremental Models Guide](https://docs.getdbt.com/docs/build/incremental-models)

### **Data Warehousing:**
- [SCD Type 2 Tutorial](https://www.sqlshack.com/implementing-slowly-changing-dimensions-scds-in-data-warehouses/)
- [Date Dimension Best Practices](https://www.kimballgroup.com/2008/09/slowly-changing-dimensions-are-not-always-as-easy-as-1-2-3/)

**Remember: These are OPTIONAL. Focus on the 3-hour delivery first!**
